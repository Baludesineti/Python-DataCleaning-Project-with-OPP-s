ðŸš€ Python Data Cleaning Project â€“ OOPâ€™s Based Data Cleaning Framework

I recently completed a hands-on project focused on building a reusable Data Cleaning framework using Object-Oriented Programming (OOP) in Python.

ðŸ“‚ Dataset: Employee Data (50 rows, 14 columns)

 ðŸ›  Tools Used: Python, Pandas, NumPy

ðŸ”Ž Key Concepts Covered:

âœ” Data Profiling & Volume Checks 
Shape validation (Row & Column count)
Data type inspection
Column listing & segregation (Numerical vs Categorical)

âœ” Missing Value Analysis
Null count & percentage calculation
Median, Mean, Mode imputation strategies
Custom imputation logic
Dropping nulls & selective column removal

âœ” Data Transformation & Cleaning
Date type conversion using pd.to_datetime()
Categorical standardisation (Gender, Marital Status mapping)
Phone number masking (PII protection)
Duplicate removal

âœ” Reusable OOP DataCleaning Class
 Designed a modular class with methods like:
volume_check()
missing_values()
impute_missing_values_median()
drop_columns()
change_date_data_type()
Phone_masking()
This improves:
Code reusability
Scalability
Maintainability
Clean ETL pipeline design

âœ” Inheritance Implementation
 Extended the base DataCleaning class using Inheritance to add advanced functionality without modifying the original class â€” demonstrating real-world OOP design principles.

ðŸ§  Technical Concepts Applied:
Object-Oriented Programming (OOP)
Class & Constructor Design
Method Encapsulation
Inheritance
Data Imputation Techniques
Data Type Normalisation
Feature Standardization
PII Masking
ETL Preprocessing Workflow

This project strengthened my understanding of how to build scalable, reusable data preprocessing systems, similar to real-world data engineering pipelines.

Iâ€™m continuously building projects in:
Python
SQL
Machine Learning
Data Engineering Concepts

Open to feedback, collaboration, and data-driven discussions ðŸš€
